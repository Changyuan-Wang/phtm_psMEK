{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec04f2e-16c3-47e2-a2ef-79bd07c9683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import solve_ivp\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feb2289-efcf-4331-8c05-c8cdfcdbcd16",
   "metadata": {},
   "source": [
    "# **I. Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73adcc91-3586-4dce-a0fc-3c81d1cf6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to read excel raw data\n",
    "def extract_data(df, df_skipped, name):\n",
    "    idx = df.columns.get_loc(f'% {name}')\n",
    "    cols = [df.columns[idx], df.columns[idx + 1]]\n",
    "    sub_df = df_skipped[cols]\n",
    "    sub_df = sub_df[\n",
    "        ~(\n",
    "            sub_df.apply(lambda row: row.map(lambda x: isinstance(x, str)) | row.isna(), axis=1)\n",
    "        ).any(axis=1)\n",
    "    ]\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26d76e55-ba4a-474d-98b0-6abadd4439c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading excel raw data, and save each experiment as name_df (e.g. control1_df)\n",
    "\n",
    "df = pd.read_excel('/path/to/psMEK_raw_scaled.xlsx', engine='openpyxl')  # change to the path of your raw data spreadsheet\n",
    "df_skipped = df.iloc[2:]\n",
    "\n",
    "names = ['control1', 'continuous', 'control2', 'A1', 'A2', 'control3', 'B1', 'B2', 'B3', 'control4', 'C1', 'C2', 'control5', 'D1', 'D2', 'D3']\n",
    "for name in names:\n",
    "    globals()[f'{name}_df'] = extract_data(df, df_skipped, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1d9e718-e5bc-4763-b4f5-26e419c5872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data have pupation times in days, now convert them to hours (hAEL)\n",
    "# save each experiment as name_expanded (e.g. control1_expanded)\n",
    "\n",
    "for name in names:\n",
    "    df_var = globals()[f'{name}_df']\n",
    "    expanded = np.repeat(\n",
    "        df_var.iloc[:, 0].astype(float).values,\n",
    "        df_var.iloc[:, 1].astype(int).values\n",
    "    ) * 24\n",
    "    globals()[f'{name}_expand'] = expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "433ae2f1-f26a-4021-b1ec-4ff6d8e4d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each treatment (perturbation), we have a paired control: control 1,2,3,4,5\n",
    "# calculate the scaling factor for each treatment (the factor that scales the mean of control group to the standard 130 hours)\n",
    "# scaling factor = 130 hours / control_mean\n",
    "\n",
    "standard_ctrl = 130\n",
    "control_names = [f'control{i}' for i in range(1, 6)]\n",
    "\n",
    "for name in control_names:\n",
    "    expand_var = globals()[f'{name}_expand']\n",
    "    mean_val = np.mean(expand_var)\n",
    "    globals()[f'{name}_mean'] = mean_val\n",
    "    globals()[f'{name}_factor'] = standard_ctrl / mean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3f21484-96b1-4ab1-a1c4-5d13081eb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that L3 starts around 70 hAEL for a control-group larva that experiences a 130-hour total development (egg to pupation)\n",
    "# Same for all treatment groups. L3 starts around 70 hAEL because our optogenetic tool only affects L3.\n",
    "\n",
    "# 1. normalization of raw data (astronomical times --> developmental times)\n",
    "# 2. convert hAEL (hours after egg lay) to AL3E (hours spent in L3)\n",
    "continuous_L3 = continuous_expand*control1_factor - 70\n",
    "A1_L3 = A1_expand*control2_factor - 70\n",
    "A2_L3 = A2_expand*control2_factor - 70\n",
    "B1_L3 = B1_expand*control3_factor - 70\n",
    "B2_L3 = B2_expand*control3_factor - 70\n",
    "B3_L3 = B3_expand*control3_factor - 70\n",
    "C1_L3 = C1_expand*control4_factor - 70\n",
    "C2_L3 = C2_expand*control4_factor - 70\n",
    "D1_L3 = D1_expand*control5_factor - 70\n",
    "D2_L3 = D2_expand*control5_factor - 70\n",
    "D3_L3 = D3_expand*control5_factor - 70\n",
    "\n",
    "# mean pupation times, hAL3E\n",
    "continuous_mean = np.mean(continuous_L3)\n",
    "A1_mean = np.mean(A1_L3)\n",
    "A2_mean = np.mean(A2_L3)\n",
    "B1_mean = np.mean(B1_L3)\n",
    "B2_mean = np.mean(B2_L3)\n",
    "B3_mean = np.mean(B3_L3)\n",
    "C1_mean = np.mean(C1_L3)\n",
    "C2_mean = np.mean(C2_L3)\n",
    "D1_mean = np.mean(D1_L3)\n",
    "D2_mean = np.mean(D2_L3)\n",
    "D3_mean = np.mean(D3_L3)\n",
    "\n",
    "# We will only use A1-B3 for fitting (optimization).\n",
    "# Calculate hours of advancement (hAL3E) for these groups\n",
    "diff_means = [60-continuous_mean, 60-A2_mean, 60-A1_mean, 60-B3_mean, 60-B2_mean, 60-B1_mean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3e62944-0256-4f16-ae3d-98d2690c413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of light on/off times (astronomical times --> developmental times)\n",
    "continuous_start = 58 * control1_factor\n",
    "continuous_end = 130\n",
    "A1_start = 58 * control2_factor\n",
    "A1_end = 88 * control2_factor\n",
    "A2_start = 88 * control2_factor\n",
    "A2_end = 118 * control2_factor\n",
    "B1_start = 70 * control3_factor\n",
    "B1_end = 85 * control3_factor\n",
    "B2_start = 85 * control3_factor\n",
    "B2_end = 100 * control3_factor\n",
    "B3_start = 100 * control3_factor\n",
    "B3_end = 115 * control3_factor\n",
    "C1_start = 75 * control4_factor\n",
    "C1_end = 107 * control4_factor\n",
    "C2_start = 91 * control4_factor\n",
    "C2_end = 123 * control4_factor\n",
    "D1_start = 74.5 * control5_factor\n",
    "D1_end = 90.5 * control5_factor\n",
    "D2_start = 90.5 * control5_factor\n",
    "D2_end = 106.5 * control5_factor\n",
    "D3_start = 106.5 * control5_factor\n",
    "D3_end = 122.5 * control5_factor\n",
    "\n",
    "# Then convert light on/off developmental times from hAEL to hAL3E\n",
    "continuous_start_L3 = 0\n",
    "continuous_end_L3 = continuous_end - 70\n",
    "A1_start_L3 = 0\n",
    "A1_end_L3 = A1_end - 70\n",
    "A2_start_L3 = A2_start - 70\n",
    "A2_end_L3 = A2_end - 70\n",
    "B1_start_L3 = 0\n",
    "B1_end_L3 = B1_end - 70\n",
    "B2_start_L3 = B2_start - 70\n",
    "B2_end_L3 = B2_end - 70\n",
    "B3_start_L3 = B3_start - 70\n",
    "B3_end_L3 = B3_end - 70\n",
    "C1_start_L3 = C1_start - 70\n",
    "C1_end_L3 = C1_end - 70\n",
    "C2_start_L3 = C2_start - 70\n",
    "C2_end_L3 = C2_end - 70\n",
    "D1_start_L3 = D1_start - 70\n",
    "D1_end_L3 = D1_end - 70\n",
    "D2_start_L3 = D2_start - 70\n",
    "D2_end_L3 = D2_end - 70\n",
    "D3_start_L3 = D3_start - 70\n",
    "D3_end_L3 = D3_end - 70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2d337-c8b7-417e-afd6-bd47fe3dbab6",
   "metadata": {},
   "source": [
    "# **II. Parameter Inference**\n",
    "The following blocks are dedicated to parameter inference (optimization) and bootstrapping. They calculate the optimal parameter set and the 95% confidence interval for the prediction data (Figure 3-4).  \n",
    "The blocks will save CSV files for each grid search. In other words, the optimal parameter set for each bootstrapped dataset will be saved, so once the process is complete, you wonâ€™t need to run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1973ed0-fb0a-4a43-8f91-a15141064226",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Functions '''\n",
    "\n",
    "# a function of bootstrapping the control & treatment groups together\n",
    "def bootstrap_delta_distributions(raw_pert_arrays, raw_ctrl_arrays, num_bootstrap=9999):\n",
    "    \n",
    "    Delta_dist = [[] for _ in range(len(raw_pert_arrays))]\n",
    "    Delta_stdv = []\n",
    "    \n",
    "    for _ in range(num_bootstrap):\n",
    "        \n",
    "        resampled_ctrl1 = np.random.choice(raw_ctrl_arrays[0], size=len(raw_ctrl_arrays[0]), replace=True)\n",
    "        resampled_ctrl2 = np.random.choice(raw_ctrl_arrays[1], size=len(raw_ctrl_arrays[1]), replace=True)\n",
    "        resampled_ctrl3 = np.random.choice(raw_ctrl_arrays[2], size=len(raw_ctrl_arrays[2]), replace=True)\n",
    "        \n",
    "        resampled_continuous = np.random.choice(raw_pert_arrays[0], size=len(raw_pert_arrays[0]), replace=True)\n",
    "        resampled_A2 = np.random.choice(raw_pert_arrays[1], size=len(raw_pert_arrays[1]), replace=True)\n",
    "        resampled_A1 = np.random.choice(raw_pert_arrays[2], size=len(raw_pert_arrays[2]), replace=True)\n",
    "        resampled_B3 = np.random.choice(raw_pert_arrays[3], size=len(raw_pert_arrays[3]), replace=True)\n",
    "        resampled_B2 = np.random.choice(raw_pert_arrays[4], size=len(raw_pert_arrays[4]), replace=True)\n",
    "        resampled_B1 = np.random.choice(raw_pert_arrays[5], size=len(raw_pert_arrays[5]), replace=True)\n",
    "\n",
    "        \n",
    "        Delta_continuous = (np.mean(resampled_ctrl1) - np.mean(resampled_continuous)) * (130 / np.mean(resampled_ctrl1))\n",
    "        Delta_A2 = (np.mean(resampled_ctrl2) - np.mean(resampled_A2)) * (130 / np.mean(resampled_ctrl2))\n",
    "        Delta_A1 = (np.mean(resampled_ctrl2) - np.mean(resampled_A1)) * (130 / np.mean(resampled_ctrl2))\n",
    "        Delta_B3 = (np.mean(resampled_ctrl3) - np.mean(resampled_B3)) * (130 / np.mean(resampled_ctrl3))\n",
    "        Delta_B2 = (np.mean(resampled_ctrl3) - np.mean(resampled_B2)) * (130 / np.mean(resampled_ctrl3))\n",
    "        Delta_B1 = (np.mean(resampled_ctrl3) - np.mean(resampled_B1)) * (130 / np.mean(resampled_ctrl3))\n",
    "                \n",
    "        Delta_dist[0].append(Delta_continuous)\n",
    "        Delta_dist[1].append(Delta_A2)\n",
    "        Delta_dist[2].append(Delta_A1)\n",
    "        Delta_dist[3].append(Delta_B3)\n",
    "        Delta_dist[4].append(Delta_B2)\n",
    "        Delta_dist[5].append(Delta_B1)\n",
    "    \n",
    "    for delta in Delta_dist:\n",
    "        Delta_stdv.append(np.std(delta))\n",
    "    \n",
    "    return Delta_dist, Delta_stdv\n",
    "\n",
    "\n",
    "# pulse function - extra signaling from the optogenetic tool\n",
    "def pulse(x, A, t0, t1):\n",
    "    return np.where((t0 <= x) & (x <= t1), A, 0)\n",
    "\n",
    "\n",
    "# the function of our ODE\n",
    "def odes(t, i, Amp, ti, tf, beta, x_stop):\n",
    "    x, y = i\n",
    "    F = 1 if x <= x_stop else 0\n",
    "    dxdt = (1/2) * x**2 + (1/2) * y - x + pulse(t, Amp, ti, tf)\n",
    "    dydt = beta * F\n",
    "    return [dxdt, dydt]\n",
    "\n",
    "\n",
    "# a function of solving for the blow-up time of one treatment\n",
    "def solve_scenario(args, i0, beta, x_stop, t_span, target_x, ctrl_time, expand, stdv):\n",
    "    solution = solve_ivp(odes, t_span, i0, args=(args[0], args[1], args[2], beta, x_stop), \n",
    "                         t_eval=np.linspace(0, t_end, 1000), max_step=0.01, method='RK45')\n",
    "    x = solution.y[0]\n",
    "    t = solution.t\n",
    "\n",
    "    if np.any(x >= target_x):\n",
    "        T_asymp = t[np.isfinite(x)].max() * 60 / ctrl_time\n",
    "        return np.sum((expand - (60-T_asymp)) ** 2 / stdv**2) # taking the difference between prediction & experimental advancement in pupation times\n",
    "    else:\n",
    "        return np.inf # if the curve never blows up, define the blow-up time as infinity\n",
    "\n",
    "\n",
    "# a function of computing the total cost function of all 6 treatments\n",
    "def cost_function(params, data_times, data_stdv):\n",
    "    beta = params[\"beta\"]\n",
    "    alpha = params[\"alpha\"]\n",
    "    x_stop = params[\"x_stop\"]\n",
    "\n",
    "    delta = 0\n",
    "    x0 = 1 - np.sqrt(1 - delta)\n",
    "    i0 = [x0, delta]\n",
    "\n",
    "    # solve the ODE for the control scenario to get control blow-up time\n",
    "    solution_ctrl = solve_ivp(odes, t_span, i0, args=(0, 0, 1, beta, x_stop), \n",
    "                              t_eval=np.linspace(0, t_end, 1000), max_step=0.01, method='RK45')\n",
    "    ctrl_x = solution_ctrl.y[0]\n",
    "    ctrl_t = solution_ctrl.t\n",
    "\n",
    "    if np.any(ctrl_x >= target_x):\n",
    "        ctrl_time = ctrl_t[np.isfinite(ctrl_x)].max()\n",
    "    else:\n",
    "        return np.inf\n",
    "\n",
    "    # use control blow-up time to find the normalized light on/off time (hAL3E) for each treatment\n",
    "    scenarios = [\n",
    "        (alpha, 0, ctrl_time),\n",
    "        (alpha, ctrl_time * A2_start_L3 / 60, ctrl_time * A2_end_L3 / 60),\n",
    "        (alpha, 0, ctrl_time * A1_end_L3 / 60),\n",
    "        (alpha, ctrl_time * B3_start_L3 / 60, ctrl_time * B3_end_L3 / 60),\n",
    "        (alpha, ctrl_time * B2_start_L3 / 60, ctrl_time * B2_end_L3 / 60),\n",
    "        (alpha, 0, ctrl_time * B1_end_L3 / 60)\n",
    "    ]\n",
    "\n",
    "    # find the total cost of all 6 treatments\n",
    "    total_cost = []\n",
    "    for args, expand, stdv in zip(scenarios, data_times, data_stdv):\n",
    "        cost = solve_scenario(args, i0, beta, x_stop, t_span, target_x, ctrl_time, expand, stdv)\n",
    "        total_cost.append(cost)\n",
    "\n",
    "    return np.sum(total_cost)\n",
    "\n",
    "\n",
    "# a function that returns the total cost associated with a given set of parameters\n",
    "def compute_cost(beta, alpha, x_stop, data_times, data_stdv):\n",
    "    cost = cost_function({'beta': beta, 'alpha': alpha, 'x_stop': x_stop}, data_times, data_stdv)\n",
    "    return beta, alpha, x_stop, cost\n",
    "\n",
    "\n",
    "# a funtion that saves all parameter values and their associated cost function into a CSV file\n",
    "def save_result(result, file_directory):\n",
    "    beta, alpha, x_stop, cost = result\n",
    "    with open(file_directory, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([beta, alpha, x_stop, cost])\n",
    "    i = np.where(beta_vals == beta)[0][0]\n",
    "    j = np.where(alpha_vals == alpha)[0][0]\n",
    "    k = np.where(x_stop_vals == x_stop)[0][0]\n",
    "    cost_matrix[i, j, k] = cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764c2e9-48ab-4cdd-aa77-b1f55db55a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap the control & treatment groups together\n",
    "Raw_pert_arrays = [continuous_expand, A2_expand, A1_expand, B3_expand, B2_expand, B1_expand]\n",
    "Raw_ctrl_arrays = [control1_expand, control2_expand, control3_expand]\n",
    "\n",
    "Delta_dist, Delta_stdv = bootstrap_delta_distributions(Raw_pert_arrays, Raw_ctrl_arrays)\n",
    "\n",
    "\n",
    "# start and end simulation times\n",
    "t_end = 10\n",
    "t_span = (0, t_end)\n",
    "\n",
    "# if the value of x never reaches this target threshold, we will call it \"never pupated\" (i.e. never reach infinity; will not blow up)\n",
    "target_x = 30\n",
    "\n",
    "\n",
    "# Parameter space that we are interested in\n",
    "# I have tried np.linspace(0, 5, 500) for all three parameters, but it was overkill in our case\n",
    "beta_vals = np.linspace(0.5, 1.2, 70)\n",
    "alpha_vals = np.linspace(0.5, 1.2, 70)\n",
    "x_stop_vals = np.linspace(1.3, 1.7, 30)\n",
    "cost_matrix = np.zeros((len(beta_vals), len(alpha_vals), len(x_stop_vals)))\n",
    "\n",
    "# create a list of all parameter combinations\n",
    "param_combinations = [(beta, alpha, x_stop) for beta in beta_vals for alpha in alpha_vals for x_stop in x_stop_vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3c59a3f-7909-40a4-8fac-3d42a1e3c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap the original data & do parameter optimization on the bootstrapped data\n",
    "\n",
    "boostrapped_index =  # we boostrapped 100 times in our case, so the number went from 1 to 100 (i.e. we repeated this block 100 times with different boostrapped indexes)\n",
    "\n",
    "data_times_bootstrapped = [Delta_dist[i][boostrapped_index] for i in range(6)]\n",
    "results_bootstrapped = Parallel(n_jobs=10, batch_size='auto')(delayed(compute_cost)(beta, alpha, x_stop, data_times_bootstrapped, Delta_stdv) for beta, alpha, x_stop in tqdm(param_combinations, desc=\"Computing Costs\"))\n",
    "\n",
    "bootstrapped_file_directory = f'/path/to/save/cost_matrix_Bootstrap{boostrapped_index}.csv' # change to your path\n",
    "\n",
    "# write an empty row at the beginning\n",
    "with open(bootstrapped_file_directory, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['', '', '', ''])\n",
    "\n",
    "# save each result incrementally\n",
    "for result in results_bootstrapped:\n",
    "    save_result(result, bootstrapped_file_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e864d41-40e1-4a08-9673-8016e46fbf87",
   "metadata": {},
   "source": [
    "# **III. Data Analysis**\n",
    "\n",
    "After obtaining the optimal parameter set, we can use it to make predictions and compare them with the experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae410d5-1b16-49bd-8245-8a724b465bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' functions '''\n",
    "\n",
    "# pulse function - extra signaling from the optogenetic tool\n",
    "def pulse(x, A, t0, t1):\n",
    "    return np.where((t0 <= x) & (x <= t1), A, 0)\n",
    "\n",
    "\n",
    "# the function of our ODE\n",
    "def odes(t, i, Amp, ti, tf, beta, x_stop):\n",
    "    x, y = i\n",
    "    F = 1 if x <= x_stop else 0\n",
    "    dxdt = (1/2) * x**2 + (1/2) * y - x + pulse(t, Amp, ti, tf)\n",
    "    dydt = beta * F\n",
    "    return [dxdt, dydt]\n",
    "\n",
    "\n",
    "# a function that calculates the 95% confidence interval for a specific duration of light exposure, and saves a CSV file\n",
    "def compute_95CI(t0, beta, alpha, x_stop, odes, t_end, duration, target_x):\n",
    "\n",
    "    y0 = 0\n",
    "    x0 = 1 - np.sqrt(1 - y0)\n",
    "    i0 = [x0, y0]\n",
    "\n",
    "    solution0 = solve_ivp(\n",
    "        odes, (0, t_end), i0,\n",
    "        args=(0, 0, 1e-10, beta, x_stop),\n",
    "        t_eval=np.linspace(0, t_end, 1000),\n",
    "        max_step=0.01\n",
    "    )\n",
    "    \n",
    "    E0 = solution0.y[0]\n",
    "    if np.any(E0 >= target_x):\n",
    "        target_t_0 = solution0.t[np.isfinite(E0)][np.argmax(E0 >= target_x)]\n",
    "    else:\n",
    "        return np.nan  # skip further calculation if target_t_0 is not found\n",
    "\n",
    "    standard_t_0 = 4.738738738738738  # number you calculated beforehand, which is the target_t_0 by using {optimized_beta, optimized_alpha, optimized_x_stop}\n",
    "    normalized_t0 = t0*target_t_0/standard_t_0\n",
    "\n",
    "    normalized_t1 = normalized_t0 + duration*target_t_0/60\n",
    "    if normalized_t1 >= target_t_0:\n",
    "        return np.nan\n",
    "\n",
    "    solution = solve_ivp(\n",
    "        odes, (0, t_end), i0,\n",
    "        args=(alpha, normalized_t0, normalized_t1, beta, x_stop),\n",
    "        t_eval=np.linspace(0, t_end, 1000),\n",
    "        max_step=0.01\n",
    "    )\n",
    "    x = solution.y[0]\n",
    "    if np.any(x >= target_x):\n",
    "        target_t = solution.t[np.isfinite(x)][np.argmax(x >= target_x)]\n",
    "        return (target_t_0 - target_t) * 60 / target_t_0\n",
    "    else:\n",
    "        return np.nan  # return NaN if the target isn't reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7107182-73ac-4881-a15c-256c9e2b810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV files obtained from bootstrapping & optimization (code section 2)\n",
    "# find the optimal parameter set at the global minimum for each bootstrapped data\n",
    "\n",
    "min_beta = []\n",
    "min_alpha = []\n",
    "min_x_stop = []\n",
    "\n",
    "for i in range(1,101):\n",
    "    file = f'/path/to/read/cost_matrix_Bootstrap{i}.csv'\n",
    "    if os.path.exists(file):\n",
    "        data = np.genfromtxt(file, delimiter=',', skip_header=1)\n",
    "        \n",
    "        min_cost_index = np.argmin(np.abs(data[:, 3]))\n",
    "        min_cost_row = data[min_cost_index]\n",
    "\n",
    "        min_beta.append(min_cost_row[0])\n",
    "        min_alpha.append(min_cost_row[1])\n",
    "        min_x_stop.append(min_cost_row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576021d3-2d3e-4a45-8947-fe4d9d5c65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "\n",
    "# calculate the average of optimal parameter sets, and use the average to make predictions\n",
    "optimized_beta = np.mean(min_beta)\n",
    "optimized_alpha = np.mean(min_alpha)\n",
    "optimized_x_stop = np.mean(x_stop)\n",
    "optimized_params = optimized_beta, optimized_alpha, optimized_x_stop\n",
    "\n",
    "\n",
    "# initial conditions\n",
    "y0 = 0\n",
    "x0 = 1 - np.sqrt(1 - y0)\n",
    "i0 = [x0, y0]\n",
    "\n",
    "# start and end simulation times\n",
    "t_end = 6\n",
    "t_span = (0, t_end) \n",
    "\n",
    "target_x = 30\n",
    "\n",
    "# find the pupation time of the control (in dimensionless time)\n",
    "solution0 = solve_ivp(odes, t_span, i0, args=(0, 0, 0+1e-10, optimized_beta, optimized_x_stop), t_eval=np.linspace(0, t_end, 1000), max_step=0.01)\n",
    "E0 = solution0.y[0]\n",
    "if np.any(E0 >= target_x):\n",
    "    target_t_0 = solution0.t[np.isfinite(E0)].max()\n",
    "else:\n",
    "    target_t_0 = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0da7ce-8ad1-45c5-bffc-17a3fbd098ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions (e.g. Figure 3B)\n",
    "\n",
    "scenarios = [\n",
    "    (optimized_alpha, 0, target_t_0, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*A2_start_L3/60, target_t_0*A2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, 0, target_t_0*A1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*B3_start_L3 /60, target_t_0*B3_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*B2_start_L3/60, target_t_0*B2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, 0, target_t_0*B1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (0, 0, 1, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*C1_start_L3/60, target_t_0*C1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*C2_start_L3/60, target_t_0*C2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*D1_start_L3/60, target_t_0*D1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*D2_start_L3/60, target_t_0*D2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "    (optimized_alpha, target_t_0*D3_start_L3/60, target_t_0*D3_end_L3/60, optimized_beta, optimized_x_stop)\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "for args in scenarios:\n",
    "    solution = solve_ivp(odes, t_span, i0, args=args, t_eval=np.linspace(0, t_end, 1000), max_step=0.01)\n",
    "    results.append((solution.t, solution.y[0]))\n",
    "\n",
    "prediction = []\n",
    "for i, (t, x) in enumerate(results):\n",
    "    if np.any(x >= target_x):\n",
    "        target_t = t[np.isfinite(x)].max()\n",
    "        prediction.append((target_t_0-target_t)*60/target_t_0)\n",
    "        print(f\"Scenario {i}: The value of t when x = {target_x} is approximately {target_t*60/target_t_0:.4f} hours, which is {(target_t_0-target_t)*60/target_t_0:.4f} hours of advancement.\")\n",
    "    else:\n",
    "        print(f\"Scenario {i}: x does not reach the value of {target_x} within the given time span.\")\n",
    "\n",
    "\n",
    "labels = [\"continuous\", \"A2\", \"A1\", \"B3\", \"B2\", \"B1\", \"Control\", \"C1\", \"C2\", \"D1\", \"D2\", \"D3\"]\n",
    "colors = [ ] # choose your own colors!\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for (t, x), label, color in zip(results, labels, colors):\n",
    "    plt.plot(t*60/target_t_0, x, label=label, color=color, marker='', linestyle='-')\n",
    "\n",
    "\n",
    "plt.xlabel('t', fontsize=12)\n",
    "plt.ylabel('x', fontsize=12)\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0, top=target_x+2)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cef69e-6097-46d8-8421-eb973f01c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate error bar (95% confidence interval) for predictions (e.g. Figure 3C)\n",
    "# This is done by using all optimal parameter sets (from bootstrapping in code section 2) to generate predictions, find the advancement in pupation times in each treatment, and then find 2.75 and 97.5 percentile among all advancements \n",
    "\n",
    "advancement_distributions = []\n",
    "\n",
    "for beta, alpha, x_stop in zip(min_beta, min_alpha, min_x_stop):\n",
    "    \n",
    "    # all 6 treatments\n",
    "    scenarios = [\n",
    "        (optimized_alpha, 0, target_t_0, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*A2_start_L3/60, target_t_0*A2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, 0, target_t_0*A1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*B3_start_L3 /60, target_t_0*B3_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*B2_start_L3/60, target_t_0*B2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, 0, target_t_0*B1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*C1_start_L3/60, target_t_0*C1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*C2_start_L3/60, target_t_0*C2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*D1_start_L3/60, target_t_0*D1_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*D2_start_L3/60, target_t_0*D2_end_L3/60, optimized_beta, optimized_x_stop),\n",
    "        (optimized_alpha, target_t_0*D3_start_L3/60, target_t_0*D3_end_L3/60, optimized_beta, optimized_x_stop)\n",
    "    ]\n",
    "    \n",
    "    # solve the ODEs for each treatment and store results\n",
    "    results = []\n",
    "    for args in scenarios:\n",
    "        solution = solve_ivp(odes, t_span, i0, args=args, t_eval=np.linspace(0, t_end, 1000), max_step=0.01)\n",
    "        results.append((solution.t, solution.y[0]))\n",
    "\n",
    "    scenario_pred = []\n",
    "    for i, (t, x) in enumerate(results):\n",
    "        if np.any(x >= target_x):\n",
    "            target_t = t[np.isfinite(x)].max()\n",
    "            scenario_pred.append((target_t_0-target_t)*60/target_t_0) # calculate advancement\n",
    "        else:\n",
    "            print(f\"Scenario {i}: x does not reach the value of {target_x} within the given time span.\")\n",
    "    \n",
    "    advancement_distributions.append(scenario_pred)\n",
    "\n",
    "\n",
    "\n",
    "# 95% confidence interval for each treatment\n",
    "pred_ci_lower = []\n",
    "pred_ci_upper = []\n",
    "\n",
    "for i in range(len(advancement_distributions[0])):\n",
    "    distribution = [sublist[i] for sublist in advancement_distributions]\n",
    "\n",
    "    ci_lower = np.percentile(distribution, 2.5)\n",
    "    ci_upper = np.percentile(distribution, 97.5)\n",
    "\n",
    "    pred_ci_lower.append(ci_lower)\n",
    "    pred_ci_upper.append(ci_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1a022d-91d8-4b06-9a88-24ba0b8c1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3C\n",
    "\n",
    "categories_AB = [\"continuous\", \"A2\", \"A1\", \"B3\", \"B2\", \"B1\"]\n",
    "prediction_AB = prediction[:6]\n",
    "diff_means = [60-continuous_mean, 60-A2_mean, 60-A1_mean, 60-B3_mean, 60-B2_mean, 60-B1_mean]\n",
    "sem_AB = [stats.sem(continuous_L3), stats.sem(A2_L3), stats.sem(A1_L3), stats.sem(B3_L3), stats.sem(B2_L3), stats.sem(B1_L3)]\n",
    "colors_AB = [ ] # choose your own colors!\n",
    "pred_ci_lower_AB = pred_ci_lower[:6]\n",
    "pred_ci_upper_AB = pred_ci_upper[:6]\n",
    "\n",
    "\n",
    "for i in range(len(diff_means)):\n",
    "    plt.errorbar(diff_means[i], prediction_AB[i], xerr=sem_AB[i], yerr=[[prediction_AB[i] - pred_ci_lower_AB[i]], [pred_ci_upper_AB[i] - prediction_AB[i]]], fmt='o', ecolor=colors_AB[i], capsize=5, color=colors_AB[i], label=categories_AB[i])\n",
    "\n",
    "\n",
    "x_fit = np.array([0, max(diff_means)+5])\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(diff_means, prediction_AB)\n",
    "fit_line = np.array(x_fit) * slope + intercept\n",
    "r_squared = r_value**2\n",
    "print(slope, intercept, r_squared)\n",
    "\n",
    "\n",
    "plt.plot(x_fit, fit_line, color='dimgray', linestyle='--')\n",
    "plt.xlabel(\"Experiment (hours)\", fontsize=12)\n",
    "plt.ylabel(\"Prediction (hours)\", fontsize=12)\n",
    "plt.title('Pupation Advancement in Experiment and Prediction', fontsize=12)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.xlim(left=0, right=20)\n",
    "plt.ylim(bottom=0, top=20)\n",
    "plt.legend(prop={'size': 9})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b56af0-076b-41fc-ab2e-14089e3d3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4A\n",
    "\n",
    "# range of t0 values that we want to start the pulse\n",
    "t0_values = np.linspace(0, t_end, 1000)\n",
    "\n",
    "# grids for pulse durations and end times\n",
    "pulse_durations = np.linspace(0, 60, 121)\n",
    "end_times = np.linspace(0, 60, 121)\n",
    "\n",
    "advancement_grid_triangle_end = np.full((len(pulse_durations), len(end_times)), np.nan)\n",
    "\n",
    "for i, duration in tqdm(enumerate(pulse_durations)):\n",
    "    for j, end_time in enumerate(end_times):\n",
    "        t0 = (end_time - duration) * target_t_0 / 60\n",
    "        t1 = end_time * target_t_0 / 60\n",
    "\n",
    "        if t0 < 0 or t1 > target_t_0:\n",
    "            continue\n",
    "\n",
    "        solution = solve_ivp(\n",
    "            odes,\n",
    "            t_span,\n",
    "            i0,\n",
    "            args=(optimized_alpha, t0, t1, optimized_beta, optimized_x_stop),\n",
    "            t_eval=np.linspace(0, t_end, 1000),\n",
    "            max_step=0.01,\n",
    "        )\n",
    "        t = solution.t\n",
    "        x = solution.y[0]\n",
    "\n",
    "        if np.any(x >= target_x):  # calculate advancement\n",
    "            target_t = t.max()\n",
    "            advancement_grid_triangle_end[i, j] = (target_t_0 - target_t) * 60 / target_t_0\n",
    "\n",
    "\n",
    "X_triangle_end, Y_triangle_end = np.meshgrid(np.linspace(0, 60, advancement_grid_triangle_end.shape[1]), np.linspace(0, 60, advancement_grid_triangle_end.shape[0]))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "contour = plt.contourf(\n",
    "    X_triangle_end,\n",
    "    Y_triangle_end,\n",
    "    advancement_grid_triangle_end,\n",
    "    levels=100,\n",
    "    cmap=\"Greens\",\n",
    ")\n",
    "\n",
    "plt.colorbar(contour, label=\"Advancement in Pupation Time (hrs)\", pad=0.12)\n",
    "\n",
    "contour = plt.contour(\n",
    "    X_triangle_end,\n",
    "    Y_triangle_end,\n",
    "    advancement_grid_triangle_end,\n",
    "    levels=10,\n",
    "    colors='black'\n",
    ")\n",
    "\n",
    "plt.clabel(contour, inline=True, fontsize=10)\n",
    "\n",
    "plt.title(\"Sensitivity Heatmap\", fontsize=12)\n",
    "plt.xlabel(\"End Time of Pulse (hrs)\", fontsize=12)\n",
    "plt.ylabel(\"Pulse Duration (hrs)\", fontsize=12)\n",
    "plt.gca().yaxis.set_label_position(\"right\")\n",
    "plt.gca().yaxis.tick_right()\n",
    "plt.tick_params(axis=\"both\", which=\"major\", labelsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7c6d3-fc6a-4c04-9651-5b0ddd6e6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 95% confidence interval for a specific duration of light exposure (e.g. Figure 4B-C)\n",
    "# After it is completed, we don't have to run this block again\n",
    "\n",
    "duration = C1_end_L3 - C1_start_L3  # same for: D1_end_L3 - D1_start_L3\n",
    "\n",
    "distributions_95CI = []\n",
    "\n",
    "param_combinations = list(zip(min_beta, min_alpha, min_x_stop))\n",
    "for t0 in tqdm(t0_values):\n",
    "    \n",
    "    current_distribution = Parallel(n_jobs=10, batch_size=\"auto\")(\n",
    "        delayed(compute_95CI)(t0, beta, alpha, x_stop, odes, t_end, duration, target_x)\n",
    "        for beta, alpha, x_stop in param_combinations\n",
    "    )\n",
    "    \n",
    "    distributions_95CI.append(current_distribution)\n",
    "\n",
    "\n",
    "with open(f\"/path/to/save/{duration}-95CI.csv\", mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([''] * len(min_beta))\n",
    "\n",
    "    for distribution in distributions_95CI:\n",
    "        writer.writerow(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe0c30-8b97-4375-a674-150009d35998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file of the 95% CI of a specific duration\n",
    "\n",
    "# different pulse durations\n",
    "C1_duration = (C1_end_L3 - C1_start_L3)*target_t_0/60\n",
    "D1_duration = (D1_end_L3 - D1_start_L3)*target_t_0/60\n",
    "\n",
    "CI_C1 = np.genfromtxt(f\"/path/to/read/{C1_duration}-95CI.csv\", delimiter=\",\", skip_header=1)\n",
    "CI_D1 = np.genfromtxt(f\"/path/to/read/{D1_duration}-95CI.csv\", delimiter=\",\", skip_header=1)\n",
    "\n",
    "pred_ci_low_C1 = []\n",
    "pred_ci_up_C1 = []\n",
    "pred_ci_low_D1 = []\n",
    "pred_ci_up_D1 = []\n",
    "\n",
    "for row in CI_C1:\n",
    "    row = row[~np.isnan(row)]\n",
    "\n",
    "    if len(row) > 0:\n",
    "        ci_low = np.percentile(row, 2.5)\n",
    "        ci_up = np.percentile(row, 97.5)\n",
    "        pred_ci_low_C1.append(ci_low)\n",
    "        pred_ci_up_C1.append(ci_up)\n",
    "\n",
    "for row in CI_D1:\n",
    "    row = row[~np.isnan(row)]\n",
    "\n",
    "    if len(row) > 0:\n",
    "        ci_low = np.percentile(row, 2.5)\n",
    "        ci_up = np.percentile(row, 97.5)\n",
    "        pred_ci_low_D1.append(ci_low)\n",
    "        pred_ci_up_D1.append(ci_up)\n",
    "\n",
    "pred_ci_low_C1 = np.array(pred_ci_low_C1)\n",
    "pred_ci_up_C1 = np.array(pred_ci_up_C1)\n",
    "pred_ci_low_D1 = np.array(pred_ci_low_D1)\n",
    "pred_ci_up_D1 = np.array(pred_ci_up_D1)\n",
    "\n",
    "pred_ci_low_combo = [pred_ci_low_C1, pred_ci_low_D1]\n",
    "pred_ci_up_combo = [pred_ci_up_C1, pred_ci_up_D1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29e18f-8f11-4945-82b1-58eb1f514249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4B-C\n",
    "\n",
    "pulses = [C1_duration, D1_duration]\n",
    "\n",
    "color_sensitivity = [\"black\", \"black\"]\n",
    "\n",
    "for duration, color, pred_ci_low, pred_ci_up in zip(pulses, color_sensitivity, pred_ci_low_combo, pred_ci_up_combo):\n",
    "    target_t_values = []\n",
    "    for t0 in tqdm(t0_values):\n",
    "        t1 = t0 + duration\n",
    "        if t1 >= target_t_0:\n",
    "            target_t_values.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        solution = solve_ivp(odes, t_span, i0, args=(optimized_alpha, t0, t1, optimized_beta, optimized_x_stop), t_eval=np.linspace(0, t_end, 1000), max_step=0.01)\n",
    "        t = solution.t\n",
    "        x = solution.y[0]\n",
    "\n",
    "        if np.any(x >= target_x):\n",
    "            target_t = t.max()\n",
    "            target_t_values.append(target_t_0 - target_t)\n",
    "        else:\n",
    "            target_t_values.append(np.nan)\n",
    "\n",
    "    # plotting advancement against end time of the pulse for each pulse duration\n",
    "    normalized_t = np.array([x*60/target_t_0 for x in target_t_values])\n",
    "    normalized_t = normalized_t[~np.isnan(normalized_t)]\n",
    "    length = len(normalized_t)\n",
    "    plt.plot((t0_values*60/target_t_0+duration*60/target_t_0)[0:length], normalized_t, color=color, marker='', linestyle='-', linewidth=1.5)\n",
    "    plt.fill_between((t0_values*60/target_t_0+duration*60/target_t_0)[0:length], pred_ci_low[0:length], pred_ci_up[0:length], color='gray', edgecolor='none', alpha=0.35) \n",
    "\n",
    "\n",
    "\n",
    "positions = [C1_end_L3, C2_end_L3, D1_end_L3, D2_end_L3, D3_end_L3,]\n",
    "data_CD = [60-C1_mean, 60-C2_mean, 60-D1_mean, 60-D2_mean, 60-D3_mean]\n",
    "sem_CD = [stats.sem(C1_L3), stats.sem(C2_L3), stats.sem(D1_L3), stats.sem(D2_L3), stats.sem(D3_L3)]\n",
    "categories_CD = [\"C1\", \"C2\", \"D1\", \"D2\", \"D3\"]\n",
    "colors_CD = [ ]  # choose your colors\n",
    "\n",
    "for i in range(len(positions)):\n",
    "    plt.errorbar(positions[i], data_CD[i], yerr=sem_CD[i], fmt='o', ecolor=colors_CD[i], capsize=5, color=colors_CD[i], label=categories_CD[i])\n",
    "    \n",
    "\n",
    "plt.xlabel('End Time of Pulse (hrs)', fontsize=12)\n",
    "plt.ylabel('Advancement in Pupation Time (hrs)', fontsize=12)\n",
    "plt.xlim(left=15, right=60)\n",
    "plt.ylim(bottom=0, top=20)\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env [~/.conda/envs/test-env/]",
   "language": "python",
   "name": "conda_test-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
